Uczenie maszynowe z pakietem mlr
========================================================
author: Mateusz Staniak
date: 30.01.2018
width: 1920
height: 1080

```{r include = FALSE}
knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE)
```

Materiały
========================================================

 - Szybkie wprowadzenie: [winietka](https://cran.r-project.org/web/packages/mlr/vignettes/mlr.html)
 - Bogata dokumentacja: [mlr](https://mlr-org.github.io/mlr-tutorial/release/html/index.html)
 - Poprzednie warsztaty STWUR: [Github/STWUR](https://github.com/STWUR/STWUR-2017-06-07), [Github/STWUR](https://github.com/STWUR/STWUR-2017-06-21)
 - Warsztaty z konferencji Why R: [Github/pzawistowski](https://github.com/pzawistowski/mlr-workshop)
 - Inne...

Dlaczego mlr?
========================================================

```{r np1, eval = FALSE}
library(randomForest)
randomForest(formula, data=NULL, ..., subset, na.action=na.fail)
```

Work flow
========================================================

- Przygotowanie danych (preprocessing)
- Zadanie (task)
- Wybór modelu (benchmark)
- Strojenie parametrów (tuning)
- Ocena modelu

Dane
========================================================

```{r dane}
library(mlr)
library(dplyr)
library(ggplot2)

mieszkania  <- read.csv("~/Dokumenty/Projekty/eRementarz4/mieszkania_wroclaw_ceny.csv")

head(mieszkania)


```

Przygotowanie danych
========================================================

Typowe zadania:

- standaryzacja danych - `normalizeFeatures`
- łączenie mało licznych poziomów zmiennych jakościowych - `mergeSmallFactorLevels`
- wybranie części obserewacji - `subsetTask`
- imputacja danych brakujących - `impute`
- i inne...

Zadania (task)
========================================================

- Obsługiwane klasy problemów
```{r taski, eval = F}
makeClassifTask()
makeRegrTask()
makeClusterTask()
makeCostSensTask()
makeMultilabelTask()
makeSurvTask()
```



Nasz problem
========================================================
```{r task_regr}
m2_task <- makeRegrTask(id = "mieszkanie",
                        data = mieszkania,
                        target = "cena_m2")
```

- Alternatywnie
```{r task_regr_nasz}
m2_task_ndz <- makeRegrTask(id = "mieszkanie_ndz",
                            data = select(mieszkania, -dzielnica),
                            target = "cena_m2")
```

Uwaga
========================================================
- `fixup.data = "warn"`: czyszczenie danych (aktualnie tylko usuwanie pustych poziomów)
- `check.data = TRUE`: sprawdzanie poprawności danych (aktualnie: NA i puste poziomy zmiennej odpowiedzi)

Metody uczenia (learner)
========================================================
- Ogromna liczba dostępnych metod
```{r methods}
listLearners(obj = "regr")[1:6, c(1, 3:4)]
```


========================================================
- Jak radzi sobie zwykła regresja liniowa?
```{r reglin}
reg_lm <- makeLearner("regr.lm")
```
- A jak inne popularne metody?
```{r otherms}
reg_rf <- makeLearner("regr.randomForest")
reg_nnet <- makeLearner("regr.nnet")
```
- Inaczej:
```{r lrns}
lrns <- makeLearners(c("lm", "randomForest", "nnet"),
                    type = "regr")
```


========================================================

- takie wywołania tworzą obiekty typu `Learner`
- metody są zaimplementowane w odpowiednich pakietach - `mlr` jest nakładką
- różne metody - różne wsparcie dla brakujących wartości, wag itd

- Uwaga: w ten sposób wszystkie hiperparametry mają ustawione wartości domyślne

Informacje o metodzie
========================================================

```{r prop}
getLearnerProperties(reg_rf)
```

```{r hyperprop}
getLearnerParamSet(reg_rf)
```


Ustawianie hiperparametrów
========================================================

- przy tworzeniu learnera:
```{r create}
reg_rf2 <- makeLearner("regr.randomForest",
                       par.vals = list(ntree = 1000))
```

- po utworzeniu learnera:
```{r add}
reg_rf2 <- setHyperPars(reg_rf, ntree = 1000)
```

```{r check}
getHyperPars(reg_rf2)
```

Porównywanie modeli
========================================================

```{r bench, eval = FALSE}
porownanie <- benchmark(learners = list(reg_lm, reg_rf, reg_nnet),
                        tasks = list(m2_task, m2_task_ndz),
                        resampling = cv5)
save(porownanie, file = "porownanie.rda")
```

```{r loadbench}
load("porownanie.rda")
porownanie
```


Wyniki porównania
========================================================

```{r wynikpor}
# getBMRAggrPerformances(porownanie)
# getBMRPerformances(porownanie)
plotBMRBoxplots(porownanie)
```


Różne kryteria
========================================================

```{r miary}
listMeasures(obj = "regr")
```


Wytrenowanie pojedynczego modelu
========================================================

- podstawowe wywołanie:
```{r rftrain, eval = FALSE}
m2_rf <- train(reg_rf2, m2_task)
```

```{r zapis, echo = FALSE, eval = FALSE}
save(m2_rf, file = "m2_rf.rda")
save(m2_rf_czesc, file = "m2_rf_czesc.rda")
```

- uwaga: można samodzielnie zdefiniować zbiór uczący
```{r sameliczby}
uczacy <- sample(1:nrow(mieszkania), floor(0.7*nrow(mieszkania)))
testowy <- setdiff(1:nrow(mieszkania), uczacy)
```

```{r rfuczacy, eval = FALSE}
m2_rf_czesc <- train(reg_rf2, m2_task, subset = uczacy)
```

```{r wczyt, echo = FALSE}
load("m2_rf.rda")
load("m2_rf_czesc.rda")
```

- przewidywane wartości:
```{r pred}
pred <- predict(m2_rf, task = m2_task)
head(getPredictionResponse(pred))
pred2 <- predict(m2_rf_czesc, newdata = mieszkania[testowy, ])
head(getPredictionResponse(pred2))
```


Strojenie parametrów
========================================================

```{r tune1}
all_params <- makeParamSet(
  makeDiscreteParam("mtry", values = 2:5),
  makeDiscreteParam("nodesize", values = seq(5, 45, by = 10))
)
```

```{r tune2, eval = FALSE}
m2_params <- tuneParams(reg_rf2, task = m2_task,
                        resampling = cv3,
                        par.set = all_params,
                        control =  makeTuneControlGrid())
```

```{zapis2, echo = FALSE, eval = FALSE}
save(m2_params, file = "m2_params.rda")
```

```{r wczyt2, echo = FALSE}
load("m2_params.rda")
```


Wynik
========================================================

```{r wyswietlpar, fig.width = 15}
m2_params
par_data <- generateHyperParsEffectData(m2_params)
plotHyperParsEffect(par_data, x = "mtry", y = "nodesize", z = "mse.test.mean", plot.type = "heatmap")
reg_rf2 <- setHyperPars(reg_rf2, mtry = 3)
```

```{r trenujznow, eval = F}
m2_rf2 <- train(reg_rf2, m2_task)
```

```{r zapis222, echo = F, eval = F}
save(m2_rf2, file = "m2_rf2.rda")
```

```{r wczyt222, echo = F}
load("m2_rf2.rda")
```

Inne kontrolki
========================================================

```{r kontrolki, eval = F}
makeTuneControlCMAES()
makeTuneControlIrace()
makeTuneControlRandom()
```


Cena mieszkania
========================================================
```{r cena}
moje <- data.frame(n_pokoj = 3L,
                   metraz = 60.00,
                   rok = 2010L,
                   pietro = 3L,
                   pietro_maks = 5L,
                   dzielnica = "Srodmiescie")
moje$dzielnica <- factor(moje$dzielnica,
                         levels = levels(mieszkania$dzielnica))
predict(m2_rf2, newdata = moje)
```


Wizualizacja modelu
========================================================

```{r pdp, eval = F}
pdp <- generatePartialDependenceData(m2_rf2,
                                     m2_task,
                                     features = colnames(mieszkania)[-c(3, 7)])
```

```{r zapis333, echo = F, eval = F}
save(pdp, file = "pdp.rda")
```

```{r wczyt333, echo = F}
load("pdp.rda")
```

```{r plotpdp, fig.width = 15}
plotPartialDependence(pdp)
```


Podziękowanie
========================================================

![Sponsor](img/kruk.jpeg)


Zachęta
========================================================

![Koduj dla Polski](img/kdp.png)


Projekt
========================================================

![Mapa](img/mapa.png)


Konkurs
========================================================

- Nagroda: wejściówka na konferencję Why R? 2018
- Co należy zrobić: podać dalej post zapowiadający kolejne spotkanie STWUR-a!

Why R? 2018
========================================================

- 2-4.07 we Wrocławiu
- Organizowany przez STWUR przy współpracy ze społecznościami R-owymi z innych części Polski
- Międzynarodowe wydarzenie (goście m.in. z Niemiec i Czech)
- Why R? 2017: ponad 200 uczestników, warsztaty, hackathon i wiele wykładów z różnych dziedzin
- Nastawiony na machine learning


STWUR
========================================================

- [https://www.facebook.com/stwur]
- [https://www.meetup.com/pl-PL/Wroclaw-R-Users-Group]
- [https://stwur.github.io/STWUR/]


========================================================

<p style="font-size: 80px;"> Po warsztatach spotykamy się w Cybermachinie! </p>

Podsumowanie
========================================================

- Tworzenie zadania: `makeRegrTask`, `makeClassifTask` itd
- Metoda uczenia: `makeLearner`, `makeLearners`
- Porównanie kilku modeli: `benchmark`
- Ustawianie hiperparametrów: `setHyperPars`
- Wytrenowanie pojedynczego modelu: `train`
- Strojenie parametrów: `tune`  - uzupełnić

Pytania, zadania, problemy
========================================================

1. Porównaj działanie swojego ulubionego modelu np. z przedstawionymi modelami. Wybierz odpowiednie kryterium.

2. Czy przekształcenie zmiennej objaśnianej może poprawić predykcje modelu? (Skośność? Obserwacje odstające?)

3. Czy umiesz zaproponować nowe zmienne, które poprawią dokładność wybranego modelu?

4. Jakie są parametry (hiperparametry) w najlepiej sprawdzającym się modelu? Spróbuj wybrać optymalne wartości dla nich.

5. Jaką cenę metra kwadratowego przewiduje wytrenowany przez Ciebie model dla mieszkania Twoich marzeń?

Bonus

6. Jak wygląda (brzegowa) zależność ceny m^2 od wieku mieszkania w wybranym przez Ciebie modelu?

7. Sensownym pytaniem jest, które mieszkania zaklasyfikujemy jako osiągalne cenowo dla przeciętnego Wrocławianina. Przyjmując za próg 300 tys. zł, dodaj zmienną oznaczającą, czy mieszkanie jest dość tanie, stwórz zadanie klasyfikacji dla tej zmiennej i wytrenuj wybrany model.
